# VisionGuardian Configuration File
# Optimized for Raspberry Pi 5 (64-bit ARM64)

# System Settings
system:
  debug_mode: false
  log_level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  log_max_size_mb: 100  # Maximum log size before rotation
  cache_auto_clean: true
  cache_max_age_hours: 24
  auto_start: true
  storage_warning_threshold_gb: 5  # Warn when less than 5GB free

# Camera Settings
camera:
  device_id: 0  # USB webcam device (run: python3 fix_logitech_camera.py to auto-detect)
  resolution_width: 640  # 640x480 for Logitech C270/C920
  resolution_height: 480
  fps: 30  # Logitech webcams support 30fps at 720p
  rotation: 0  # 0, 90, 180, 270
  flip_horizontal: false
  flip_vertical: false
  auto_focus: true
  brightness: 50  # 0-100 (50 = camera default)
  contrast: 50    # 0-100 (50 = camera default)
  saturation: 50  # 0-100 (50 = camera default)
  auto_white_balance: true  # Auto white balance for natural colors
  auto_exposure: true  # Auto exposure for varying lighting
  raw_mode: false  # FALSE = enable processing (USB cameras usually work better with this)
  # Color correction (DISABLED - camera defaults are perfect)
  color_correction:
    enabled: false  # Disabled - use camera's native colors
    brightness_adjust: 0
    contrast_adjust: 0
    saturation_adjust: 0
    gamma: 1.0  # 0.5-2.0, 1.0 = no change

# Audio Settings
audio:
  engine: "pyttsx3"  # pyttsx3 or gtts
  voice_speed: 160  # Words per minute
  volume: 0.9  # 0.0 to 1.0
  language: "en"  # Language code
  output_device: "default"  # Audio output device
  enable_audio_cues: true
  priority_interrupt: true  # Higher priority announcements interrupt lower ones

# Voice Assistant Settings
voice_assistant:
  enabled: false  # Set to true to use voice commands (requires microphone)
  wake_word: "hey guardian"  # Wake word for voice activation
  timeout_seconds: 5  # Listening timeout
  ambient_noise_duration: 1  # Calibration time for ambient noise
  energy_threshold: 4000  # Adjust based on environment

# Automatic Mode Settings (when voice assistant disabled)
automatic_mode:
  description_interval_seconds: 10  # How often to announce scene (10 seconds)
  announce_objects: true  # Announce detected objects automatically
  announce_people: true  # Announce detected people automatically
  announce_text: false  # Set to true to auto-read text (can be verbose)

# Facial Recognition Settings
facial_recognition:
  enabled: true
  model: "hog"  # hog (faster on CPU) or cnn (more accurate but slower)
  tolerance: 0.6  # Lower = stricter matching (0.0-1.0)
  recognition_interval_seconds: 2  # Minimum time between recognitions
  max_faces_in_frame: 5
  announce_unknown: false
  save_unknown_faces: false
  encoding_model: "small"  # small or large

# Enhanced Object Detection Settings (YOLOv8 - FREE, 300+ objects)
enhanced_object_detection:
  enabled: true  # Use YOLOv8 for better detection (recommended)
  model_size: "n"  # n (nano), s (small), m (medium), l (large), x (extra-large)
  confidence_threshold: 0.5
  iou_threshold: 0.45
  max_detections: 10
  detection_interval_seconds: 1

# Basic Object Detection Settings (fallback, 80 COCO objects)
object_detection:
  enabled: true
  model_type: "tflite"  # tflite or onnx
  model_path: "ssd_mobilenet_v2_coco_quant.tflite"
  labels_path: "coco_labels.txt"
  confidence_threshold: 0.5  # 0.0-1.0
  detection_interval_seconds: 1
  max_objects_announce: 3  # Only announce top 3 objects
  filter_classes: []  # List of class IDs to filter, empty = all
  nms_threshold: 0.5  # Non-maximum suppression threshold

# OCR Settings
ocr:
  enabled: true
  engine: "tesseract"  # tesseract or easyocr
  languages: ["eng"]  # Language codes
  confidence_threshold: 60  # 0-100
  preprocessing: true  # Apply image preprocessing
  detect_orientation: true
  announcement_mode: "sentences"  # sentences, words, or full

# AI Vision Settings (Cloud-based, requires internet and API key)
ai_vision:
  enabled: false  # Set to true to use AI-powered vision (more accurate)
  primary_service: "openai"  # openai or google
  openai_api_key: ""  # Get from https://platform.openai.com/api-keys
  google_credentials_path: ""  # Path to Google Cloud credentials JSON
  detail_level: "high"  # low, medium, high
  fallback_to_local: true  # Use local models if API fails
  min_interval_seconds: 2  # Minimum time between API calls
  max_retries: 2
  timeout_seconds: 10

# Scene Description Settings (Local, offline)
scene_description:
  enabled: true
  model_path: "scene_classifier_quantized.tflite"
  description_interval_seconds: 5
  detail_level: "medium"  # low, medium, high
  include_lighting: true
  include_location_type: true

# Obstacle Detection Settings
obstacle_detection:
  enabled: true
  min_distance_cm: 150  # Alert when obstacle within 150cm
  warning_distance_cm: 100  # Critical warning distance
  detection_zones: 3  # Left, Center, Right
  alert_interval_seconds: 2
  use_depth_estimation: true
  depth_model_path: "midas_v21_small_256_quantized.tflite"

# Currency Detection Settings
currency_detection:
  enabled: true
  supported_currencies: ["USD", "EUR", "GBP"]  # Add more as needed
  model_path: "currency_classifier_quantized.tflite"
  confidence_threshold: 0.7
  announcement_format: "detailed"  # simple or detailed

# Color Detection Settings
color_detection:
  enabled: true
  mode: "dominant"  # dominant, precise, or palette
  color_space: "rgb"  # rgb or hsv
  num_colors: 3  # Number of dominant colors to detect
  announce_shade: true  # e.g., "light blue" vs "blue"

# Feature Priority (1=highest, 10=lowest)
priorities:
  emergency_detection: 1
  obstacle_detection: 2
  facial_recognition: 3
  currency_detection: 4
  object_detection: 5
  color_detection: 6
  ocr: 7
  scene_description: 8

# Emergency Detection Settings
emergency_detection:
  enabled: true
  detect_fire: true
  detect_medical_symbols: true
  detect_warning_signs: true
  alert_repeat_interval_seconds: 10
  emergency_contact: null  # Phone number for alerts (future feature)

# Navigation Assistance Settings
navigation:
  enabled: false  # Future feature - requires GPS/compass
  cardinal_directions: true
  announce_turns: true
  waypoint_alerts: true

# Performance Settings
performance:
  enable_threading: true
  max_threads: 4
  gpu_acceleration: false  # Set to true if GPU available
  model_quantization: "int8"  # int8, fp16, or none
  frame_skip: 2  # Process every Nth frame
  enable_profiling: false

# Storage Management
storage:
  auto_cleanup: true
  keep_logs_days: 7
  keep_cache_hours: 24
  backup_known_faces: true
  models_compression: true

# UI/UX Settings
user_experience:
  verbosity: "medium"  # low, medium, high
  announcement_queue_size: 5
  rapid_update_mode: false
  haptic_feedback: false  # Future feature - requires hardware
  led_indicators: true  # Use GPIO LEDs for status

# Advanced Settings
advanced:
  enable_model_warmup: true  # Load models at startup
  watchdog_enabled: true  # Auto-restart on crash
  telemetry: false  # Anonymous usage statistics
  experimental_features: false
